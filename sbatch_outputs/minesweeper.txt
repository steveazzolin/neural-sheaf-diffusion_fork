wandb: Currently logged in as: mcstewe. Use `wandb login --relogin` to force relogin
Downloading https://github.com/yandex-research/heterophilous-graphs/raw/main/data/minesweeper.npz
Processing...
Done!
wandb: Currently logged in as: mcstewe. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.1
wandb: Run data is saved locally in /home/steve.azzolin/sheafs/neural-sheaf-diffusion_fork/wandb/run-20230801_170232-w7ucvts8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-bush-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/mcstewe/sheaf
wandb: üöÄ View run at https://wandb.ai/mcstewe/sheaf/runs/w7ucvts8
Running with wandb account: mcstewe
Namespace(epochs=1000, lr=0.01, weight_decay=0.00011215791366362148, sheaf_decay=0.00011215791366362148, early_stopping=100, min_acc=0.0, stop_strategy='acc', d=3, layers=5, normalised=True, deg_normalised=False, linear=False, hidden_channels=32, input_dropout=0.7, dropout=0.0, left_weights=True, right_weights=True, add_lp=True, add_hp=False, use_act=True, second_linear=True, orth='householder', sheaf_act='tanh', edge_weights=True, sparse_learner=False, dataset='minesweeper', seed=43, cuda=0, folds=3, model='BundleSheaf', entity='mcstewe', evectors=0, max_t=1.0, int_method=None, step_size=1, max_iters=100, adjoint_method='adaptive_heun', adjoint=False, adjoint_step_size=1, tol_scale=1.0, tol_scale_adjoint=1.0, max_nfe=1000, no_early=False, earlystopxT=3, max_test_steps=100, sha='11e21b561d884713ab1a18a521a7dc2fb26b9361', graph_size=10000, input_dim=7, output_dim=2, device=device(type='cuda', index=0))
  0%|          | 0/3 [00:00<?, ?it/s]/home/steve.azzolin/anaconda3/envs/nsd/lib/python3.9/site-packages/torch/cuda/__init__.py:145: UserWarning: 
NVIDIA A100-SXM4-80GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the NVIDIA A100-SXM4-80GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
 33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [06:16<12:33, 376.55s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [07:01<03:01, 181.31s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [08:05<00:00, 127.92s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [08:05<00:00, 161.86s/it]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: / 0.010 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: - 0.010 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: | 0.012 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: / 0.019 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: - 0.019 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: \ 0.019 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: | 0.019 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: / 0.019 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: - 0.019 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: \ 0.019 MB of 0.019 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          best_epoch ‚ñÉ‚ñÅ‚ñà
wandb:       best_test_acc ‚ñà‚ñÅ‚ñà
wandb:        best_val_acc ‚ñÜ‚ñÅ‚ñà
wandb:  fold0_tmp_test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÑ
wandb: fold0_tmp_test_loss ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     fold0_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÖ
wandb:    fold0_train_loss ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       fold0_val_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ
wandb:      fold0_val_loss ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test_acc ‚ñÅ
wandb:        test_acc_std ‚ñÅ
wandb:             val_acc ‚ñÅ
wandb: 
wandb: Run summary:
wandb:          best_epoch 343
wandb:       best_test_acc 0.8168
wandb:        best_val_acc 0.8164
wandb:  fold0_tmp_test_acc 0.8072
wandb: fold0_tmp_test_loss 0.36891
wandb:     fold0_train_acc 0.8066
wandb:    fold0_train_loss 0.36467
wandb:       fold0_val_acc 0.8024
wandb:      fold0_val_loss 0.37849
wandb:            test_acc 81.17333
wandb:        test_acc_std 0.745
wandb:             val_acc 81.01333
wandb: 
wandb: Synced fluent-bush-2: https://wandb.ai/mcstewe/sheaf/runs/w7ucvts8
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230801_170232-w7ucvts8/logs
Fold 0 | Epochs: 255 | Best epoch: 155
Test acc: 0.8172
Best val acc: 0.8116
Laplacian 0: Max: 0.0001, Min: -0.0006, Avg: -0.0000, Abs avg: 0.0000
Laplacian 1: Max: 0.0000, Min: -0.0006, Avg: -0.0000, Abs avg: 0.0000
Laplacian 2: Max: 0.0000, Min: -0.0002, Avg: -0.0000, Abs avg: 0.0000
Laplacian 3: Max: 0.0471, Min: -0.9828, Avg: -0.0390, Abs avg: 0.0394
Laplacian 4: Max: 0.0001, Min: -0.0003, Avg: -0.0000, Abs avg: 0.0000
Epsilons 0: [-0.03  -0.055 -0.04  -0.082]
Epsilons 1: [-0.05  -0.054 -0.019 -0.095]
Epsilons 2: [-0.049 -0.053 -0.019 -0.167]
Epsilons 3: [-0.067 -0.063 -0.043 -0.124]
Epsilons 4: [-0.044 -0.053 -0.037 -0.11 ]
Fold 1 | Epochs: 165 | Best epoch: 65
Test acc: 0.8012
Best val acc: 0.8024
Laplacian 0: Max: 0.0009, Min: -0.0098, Avg: -0.0000, Abs avg: 0.0000
Laplacian 1: Max: 0.0001, Min: -0.0006, Avg: -0.0000, Abs avg: 0.0000
Laplacian 2: Max: 0.6837, Min: -0.9113, Avg: -0.0317, Abs avg: 0.0497
Laplacian 3: Max: 0.4603, Min: -0.8832, Avg: -0.0027, Abs avg: 0.0042
Laplacian 4: Max: 0.0000, Min: -0.0004, Avg: -0.0000, Abs avg: 0.0000
Epsilons 0: [-0.099 -0.076 -0.108 -0.087]
Epsilons 1: [-0.102 -0.07  -0.102 -0.131]
Epsilons 2: [-0.089 -0.073 -0.129 -0.069]
Epsilons 3: [-0.09  -0.075 -0.102 -0.039]
Epsilons 4: [-0.096 -0.082 -0.121 -0.079]
Fold 2 | Epochs: 443 | Best epoch: 343
Test acc: 0.8168
Best val acc: 0.8164
Laplacian 0: Max: 0.0027, Min: -0.0380, Avg: -0.0003, Abs avg: 0.0003
Laplacian 1: Max: 0.0006, Min: -0.0023, Avg: -0.0002, Abs avg: 0.0003
Laplacian 2: Max: 0.4518, Min: -0.6178, Avg: -0.0018, Abs avg: 0.0043
Laplacian 3: Max: 0.0214, Min: -0.9861, Avg: -0.0137, Abs avg: 0.0138
Laplacian 4: Max: 0.5169, Min: -0.9915, Avg: -0.0934, Abs avg: 0.1374
Epsilons 0: [-0.068 -0.048 -0.027 -0.077]
Epsilons 1: [-0.068 -0.048 -0.026 -0.092]
Epsilons 2: [-0.064 -0.056 -0.031 -0.153]
Epsilons 3: [-0.066 -0.056 -0.018 -0.084]
Epsilons 4: [-0.06  -0.036 -0.027 -0.099]
BundleSheaf on minesweeper | SHA: 11e21b561d884713ab1a18a521a7dc2fb26b9361
Test acc: 81.1733 +/- 0.7450 | Val acc: 81.0133
DONE
Execution lasted 8 minutes
